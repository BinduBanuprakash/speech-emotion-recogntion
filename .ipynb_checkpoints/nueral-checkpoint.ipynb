{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Amrutha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Amrutha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Amrutha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Amrutha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Amrutha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Amrutha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM as KERAS_LSTM, Dense, Dropout, Conv2D, Flatten, \\\n",
    "    BatchNormalization, Activation, MaxPooling2D\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from keras import callbacks\n",
    "%run Model.ipynb\n",
    "\n",
    "class LossHistory(callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "\n",
    "class DNN(Model):\n",
    "    \n",
    "    def __init__(self, input_shape, num_classes, **params):\n",
    "        \n",
    "#         print(\"amru\")\n",
    "        super(DNN, self).__init__(**params)\n",
    "        self.input_shape = input_shape\n",
    "        self.model = Sequential()\n",
    "        self.make_default_model()\n",
    "        self.model.add(Dense(num_classes, activation='softmax'))\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "                           metrics=['accuracy'])\n",
    "        print(self.model.summary(), file=sys.stderr)\n",
    "        self.save_path = self.save_path or self.name + '_best_model.h5'\n",
    "        self.loss_values = []         \n",
    "\n",
    "    def load_model(self, to_load):\n",
    "        \n",
    "        try:\n",
    "            self.model.load_weights(to_load)\n",
    "        except:\n",
    "            sys.stderr.write(\"Invalid saved file provided\")\n",
    "            sys.exit(-1)\n",
    "\n",
    "    def save_model(self):\n",
    "        \n",
    "        # lets assume `model` is main model \n",
    "        model_json = self.model.to_json()\n",
    "        with open(\"model_in_json.json\", \"w\") as json_file:\n",
    "            json.dump(model_json, json_file)\n",
    "\n",
    "        self.model.save_weights(self.save_path)\n",
    "\n",
    "\n",
    "    def train(self, x_train, y_train, x_val=None, y_val=None, n_epochs=50):\n",
    "        \n",
    "        best_acc = 0\n",
    "        history = LossHistory()\n",
    "        if x_val is None or y_val is None:\n",
    "            x_val, y_val = x_train, y_train\n",
    "        for i in range(n_epochs):\n",
    "            \n",
    "            p = np.random.permutation(len(x_train))\n",
    "            x_train = x_train[p]\n",
    "            y_train = y_train[p]\n",
    "            self.model.fit(x_train, y_train, batch_size=32, epochs=1,callbacks=[history])\n",
    "            loss, acc = self.model.evaluate(x_val, y_val)\n",
    "            self.loss_values.append(sum(history.losses)/len(history.losses))\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "        self.trained = True\n",
    "        return self.loss_values\n",
    "\n",
    "    def predict_one(self, sample):\n",
    "        if not self.trained:\n",
    "            sys.stderr.write(\n",
    "                \"Model should be trained or loaded before doing predict\\n\")\n",
    "            sys.exit(-1)\n",
    "        return np.argmax(self.model.predict(np.array([sample])))\n",
    "\n",
    "    def make_default_model(self) -> None:\n",
    "      \n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class LSTM(DNN):\n",
    "    \n",
    "\n",
    "    def __init__(self, **params):\n",
    "        params['name'] = 'LSTM'\n",
    "        super(LSTM, self).__init__(**params)\n",
    "\n",
    "    def make_default_model(self):\n",
    "        \n",
    "        print(\"sfs\")\n",
    "        self.model.add(KERAS_LSTM(128,\n",
    "                       input_shape=(self.input_shape[0], self.input_shape[1])))\n",
    "        self.model.add(Dropout(0.5))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(32, activation='relu'))\n",
    "        self.model.add(Dense(16, activation='tanh'))\n",
    "        \n",
    "    def plot_curve(self):\n",
    "        epochs = range(1, len(self.loss_values)+1)\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        plt.plot(epochs, self.loss_values, label='Training Loss of lstm')\n",
    "        plt.title('Training Loss of lstm')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        fig.savefig('training_loss_of_lstm.png')\n",
    "    \n",
    "    def get_bias_weights(self):\n",
    "        units = int(int(self.model.layers[0].trainable_weights[0].shape[1])/4)\n",
    "        weights = self.model.layers[0].get_weights()[0]\n",
    "        biases = self.model.layers[0].get_weights()[1]\n",
    "        return weights, biases, units\n",
    "    \n",
    "    def predict(self, samples: numpy.ndarray) -> Tuple:\n",
    "        \n",
    "        results = []\n",
    "        for _, sample in enumerate(samples):\n",
    "            results.append(self.predict_one(sample))\n",
    "        return tuple(results)\n",
    "    \n",
    "    from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "    def plot_confusion_matrix(self,y_true, y_pred, classes,\n",
    "                              normalize=True,\n",
    "                              title=None,\n",
    "                              cmap=plt.cm.Blues):\n",
    "       \n",
    "        if not title:\n",
    "            if normalize:\n",
    "                title = 'Normalized confusion matrix'\n",
    "            else:\n",
    "                title = 'Confusion matrix, without normalization'\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        # Only use the labels that appear in the data\n",
    "        classes = classes[unique_labels(y_true, y_pred)]\n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            print(\"Normalized confusion matrix\")\n",
    "        else:\n",
    "            print('Confusion matrix, without normalization')\n",
    "\n",
    "        print(cm)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        ax.figure.colorbar(im, ax=ax)\n",
    "        \n",
    "        ax.set(xticks=np.arange(cm.shape[1]),\n",
    "               yticks=np.arange(cm.shape[0]),\n",
    "               \n",
    "               xticklabels=classes, yticklabels=classes,\n",
    "               title=title,\n",
    "               ylabel='True label',\n",
    "               xlabel='Predicted label')\n",
    "\n",
    "        # Rotate the tick labels and set their alignment.\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "                 rotation_mode=\"anchor\")\n",
    "\n",
    "        # Loop over data dimensions and create text annotations.\n",
    "        fmt = '.2f' if normalize else 'd'\n",
    "        thresh = cm.max() / 2.\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                ax.text(j, i, format(cm[i, j], fmt),\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        fig.tight_layout()\n",
    "        return ax\n",
    "     \n",
    "    def evaluate(self, x_test, y_test):\n",
    "        y_pred = self.predict(x_test)\n",
    "        cm = confusion_matrix(y_test,y_pred)\n",
    "        accuracy = accuracy_score(y_test,y_pred)\n",
    "        print(\"confusion matrics=\",cm)\n",
    "        print(\"  \")\n",
    "        print(\" accuracy=\",accuracy*100)\n",
    "        emotionclassname = np.asarray([\"Neutral\", \"Angry\", \"Happy\", \"Sad\"])\n",
    "        self.plot_confusion_matrix(y_test, y_pred, classes=emotionclassname, normalize=True,\n",
    "                      title='Normalized confusion matrix for LSTM')\n",
    "        return accuracy  \n",
    "    \n",
    "        \n",
    "class MLP():\n",
    "    \n",
    "    def __init__(self, **params):\n",
    "        params['name'] = 'Neural Network'\n",
    "        self.model = MLPClassifier(activation='logistic', verbose=True,\n",
    "                                   hidden_layer_sizes=(512,), batch_size=32)\n",
    "        \n",
    "    \n",
    "    def train(self, x_train, y_train):\n",
    "        history = self.model.fit(x_train, y_train)\n",
    "        pickle.dump(self.model, open('ANN_model_.h5', \"wb\"))\n",
    "        return self.model.loss_curve_\n",
    "    \n",
    "    def plot_curve(self):\n",
    "        loss_values = self.model.loss_curve_\n",
    "        epochs = range(1, len(loss_values)+1)\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        plt.plot(epochs, loss_values, label='Training Loss of mlp')\n",
    "        plt.title('Training Loss of mlp')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        fig.savefig('training_loss_of_mlp.png')\n",
    "                \n",
    "    from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "    def plot_confusion_matrix(self,y_true, y_pred, classes,\n",
    "                              normalize=True,\n",
    "                              title=None,\n",
    "                              cmap=plt.cm.Blues):\n",
    "        \n",
    "        if not title:\n",
    "            if normalize:\n",
    "                title = 'Normalized confusion matrix'\n",
    "            else:\n",
    "                title = 'Confusion matrix, without normalization'\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        # Only use the labels that appear in the data\n",
    "        classes = classes[unique_labels(y_true, y_pred)]\n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            print(\"Normalized confusion matrix\")\n",
    "        else:\n",
    "            print('Confusion matrix, without normalization')\n",
    "\n",
    "        print(cm)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        ax.figure.colorbar(im, ax=ax)\n",
    "        \n",
    "        ax.set(xticks=np.arange(cm.shape[1]),\n",
    "               yticks=np.arange(cm.shape[0]),\n",
    "              \n",
    "               xticklabels=classes, yticklabels=classes,\n",
    "               title=title,\n",
    "               ylabel='True label',\n",
    "               xlabel='Predicted label')\n",
    "\n",
    "        # Rotate the tick labels and set their alignment.\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "                 rotation_mode=\"anchor\")\n",
    "\n",
    "        # Loop over data dimensions and create text annotations.\n",
    "        fmt = '.2f' if normalize else 'd'\n",
    "        thresh = cm.max() / 2.\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                ax.text(j, i, format(cm[i, j], fmt),\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        fig.tight_layout()\n",
    "        return ax\n",
    "     \n",
    "    def evaluate(self, x_test, y_test):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        cm = confusion_matrix(y_test,y_pred)\n",
    "        accuracy = accuracy_score(y_test,y_pred)\n",
    "        print(\"confusion matrics=\",cm)\n",
    "        print(\"  \")\n",
    "        print(\" accuracy=\",accuracy*100)\n",
    "        emotionclassname = np.asarray([\"Neutral\", \"Angry\", \"Happy\", \"Sad\"])\n",
    "        self.plot_confusion_matrix(y_test, y_pred, classes=emotionclassname, normalize=True,\n",
    "                      title='Normalized confusion matrix for MLP')\n",
    "        return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
